{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9d1f5d96-0846-4187-9422-8d98bd49fbd1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Data Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c6ca9843-5a9a-4bc0-b971-46799a29a8c7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "proj_df = spark.read.csv(\"/Volumes/workspace/hrd/rawfiles/Project.csv\", header=True, inferSchema=True)\n",
    "loc_df = spark.read.csv(\"/Volumes/workspace/hrd/rawfiles/Location.csv\", header=True, inferSchema=True)\n",
    "grade_df = spark.read.csv(\"/Volumes/workspace/hrd/rawfiles/Grade.csv\", header=True, inferSchema=True)\n",
    "dept_df = spark.read.csv(\"/Volumes/workspace/hrd/rawfiles/Dept.csv\", header=True, inferSchema=True)\n",
    "ass_df = spark.read.csv('/Volumes/workspace/hrd/rawfiles/Associate*.csv', header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e8c0c922-d093-4a01-9b58-1126c48e497b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Get Current Month data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "674f7224-b214-493e-8980-5c996ef2d225",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from datetime import datetime\n",
    "ass_df=ass_df.filter((ass_df['year'] == datetime.now().strftime(\"%Y\")) & (ass_df['month'] == '06'))\n",
    "\n",
    "ass_df = ass_df.join(proj_df, ass_df.projectid == proj_df.projectid, 'inner').drop(proj_df.projectid).join(loc_df, ass_df.locationid == loc_df.locationid, 'inner').drop(loc_df.locationid).join(dept_df, ass_df.departmentcode == dept_df.deptcode, 'inner').drop(dept_df.deptcode).join(grade_df, ass_df.gradecode == grade_df.gradecode, 'inner').drop(grade_df.gradecode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "78cc723d-bd20-4dfa-94e9-cf8e8d1f19ab",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##Start & End of Month values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a300e44d-d6ab-4d06-86c9-f9ea5697fdf1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from pyspark.sql.functions import trunc, current_date,last_day\n",
    "from pyspark.sql.types import DateType\n",
    "\n",
    "# Create a DataFrame with current_date\n",
    "df = spark.range(1).select(trunc(current_date(), \"MM\").alias(\"start_of_month\"))\n",
    "\n",
    "# Collect the literal value\n",
    "start_date_literal = df.collect()[0][\"start_of_month\"]\n",
    "\n",
    "print(start_date_literal)  # Output: e.g., 2025-07-01\n",
    "df = spark.range(1).select(last_day(current_date()).alias(\"end_of_month\"))\n",
    "\n",
    "# Collect the literal value\n",
    "end_date_literal = df.collect()[0][\"end_of_month\"]\n",
    "\n",
    "print(end_date_literal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7f079a79-5a05-4684-9c30-fa257b22cc5e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import when, col, lit, trim,to_date\n",
    "ass_df_att =ass_df.withColumn(\n",
    "    \"resignationdate\",\n",
    "    when(\n",
    "        (col(\"resignationdate\").isNull()) |\n",
    "        (trim(col(\"resignationdate\")) == \"\") |\n",
    "        (trim(col(\"resignationdate\")).isin(\"NA\", \"null\", \"NULL\",\"None\")),\n",
    "        lit(\"0001-01-01\")\n",
    "    ).otherwise(col(\"resignationdate\"))).withColumn(\n",
    "    \"resignationdate\",\n",
    "    to_date(col(\"resignationdate\"), \"yyyy-MM-dd\"))\n",
    "display(ass_df_att)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6e793f5d-433b-463d-bd38-b6c80ebadb24",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "ass_df_att = ass_df_att.filter(col(\"resignationdate\")!='0001-01-01').filter(col(\"resignationdate\") <= end_date_literal).filter(col(\"resignationdate\") >= start_date_literal)\n",
    "display(ass_df_att)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a765d924-f9b6-4376-8b33-88e8197ee984",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#Write data processed files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b767b932-725c-49e7-954d-92be9d79162c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "ass_df.write.mode(\"overwrite\").csv(\"/Volumes/workspace/hrd/processedfiles/Associates.csv\")\n",
    "ass_df.write.mode(\"overwrite\").csv(\"/Volumes/workspace/hrd/processedfiles/Resigned_Associates.csv\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 6397247263307302,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Ingest Raw data",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
